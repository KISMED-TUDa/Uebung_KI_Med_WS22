{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mQlUOuAbcyu4",
        "e5qP03NRc-Ev"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQlUOuAbcyu4"
      },
      "source": [
        "# 1. Metriken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xGWKASOc9iw"
      },
      "source": [
        "**a)** Führe die folgende Zelle aus, um eine Confusion Matrix zu erhatlten. Bestimme daraus die Prävalenz, den Bias, die Sensitivität und Spezifität, sowie Precision und Recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Is3Z1T1xPaSI",
        "cellView": "form"
      },
      "source": [
        "#@title Der Code ist hier nicht weiter interessant, ihr braucht die Zelle einfach nur auszuführen.\n",
        "import numpy as np\n",
        "import random as rd\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "rd.seed(0)\n",
        "\n",
        "fraction_negatives = 0.42\n",
        "gesamtmenge = 200\n",
        "\n",
        "y_true=np.concatenate((np.ones((1,int(gesamtmenge*(1-fraction_negatives)))),np.zeros((1,int(gesamtmenge*fraction_negatives)))),1).T\n",
        "positive_pred_distribution = np.array([min(1,rd.gauss(0.75,0.25)) for i in range(0,int(gesamtmenge*(1-fraction_negatives)))])\n",
        "negative_pred_distribution = np.array([max(0,rd.gauss(0.33,0.2)) for i in range(0,int(gesamtmenge*fraction_negatives))])\n",
        "predictions = np.concatenate((positive_pred_distribution,negative_pred_distribution),0)\n",
        "y_hat = predictions >= 0.66\n",
        "conf_mat = pd.DataFrame(confusion_matrix(y_true,y_hat), index=[\"negativ\",\"positiv\"],columns=[\"'negativ' klassifiziert\", \"'positiv' klassifiziert\"])\n",
        "conf_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CCw_uIxVRHy"
      },
      "source": [
        "Prävalenz: $p = \\frac{50+66}{50+66+79+5} = \\frac{116}{200} = 0.58$\n",
        "\n",
        "Bias: $b = \\frac{5+61}{50+66+79+5} = \\frac{71}{200} = 0.355$\n",
        "\n",
        "Sensitivität: $sens = \\frac{66}{116} = 0.569$\n",
        "\n",
        "Spezifität: $spez = \\frac{79}{84} = 0.940$\n",
        "\n",
        "Precision: $prec = \\frac{66}{71} = 0.930$\n",
        "\n",
        "Recall: $rec = sens = 0.569$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZU3OHGJksN3"
      },
      "source": [
        "**b)** Angenommen, ein Klassifikator hat eine Sensitivität von $0.86$, eine Spezifität von $0.85$ und einen F1-Score von $0.12$. Wie groß ist die Prävalenz $p$?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igenfq0vlG-H"
      },
      "source": [
        "Aus F1 und Sensitivität lässt sich ein Wert für die Precision berechnen:\n",
        "\n",
        "$F1=2\\frac{prec*sens}{prec+sens} = 2\\frac{prec\\cdot 0.86}{prec+0.86} \\overset{!}{=} 0.12$\n",
        "\n",
        "$\\Rightarrow 0.12\\left(prec+0.86\\right) = 2\\cdot 0.86\\cdot prec$\n",
        "\n",
        "$\\Rightarrow prec = 0.0645 $\n",
        "\n",
        "Mit der Grundmenge $G$ lässt sich dann die Precision nach der Prävalenz $p$ umstellen:\n",
        "\n",
        "$prec=\\frac{TP}{PP}=\\frac{TP}{TP+FP}=\\frac{sens\\cdot P}{sens\\cdot P+(1-spez)N} = \\frac{sens\\cdot p\\cdot G}{sens\\cdot p\\cdot G+(1-spez)(1-p)G} = \\frac{sens\\cdot p}{sens\\cdot p+(1-spez)(1-p)}= \\frac{0.86p}{0.86p+(1-0.85)(1-p)} = \\frac{0.86p}{0.71p+0.15} \\overset{!}{=} 0.0645$\n",
        "\n",
        "$\\Rightarrow 0.0645\\left(0.71p+0.15\\right) = 0.86p$\n",
        "\n",
        "$\\Rightarrow p = \\frac{0.0645\\cdot 0.15}{0.86-0.0645\\cdot 0.71} ≈ 0.01188 = 1.188$%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE5Wqc2Qedfl"
      },
      "source": [
        "Führe die nächste Zelle aus. Der Code ist absichtlich ausgeblendet, da ihr ihn für diese Übung nicht zu verstehen braucht. Die Zelle erstellt einen Plot, den man interaktiv über einen Schieberegler verändern kann. Der Plot visualisiert das letzte Layer eines Neuronalen Netzes, das eine Klassifikation vornimmt. Das Layer besteht aus einer Sigmoid-Funktion, die die Inputs (repräsentiert durch die senkrechten Striche) in Wahrscheinlichkeiten, also Werte zwischen 0 und 1 umrechnet. Die Farbe der Striche codiert, ob es sich um einen positiven (gelb) oder einen negativen (blau) Wert handelt. Der grüne, wagrechte Strich repräsentiert die Grenze $\\alpha$, ab der Werte als positiv klassifiziert werden. Über den Schieberegler kann man $\\alpha$ zwischen 0.01 und 0.99 verschieben. \n",
        "\n",
        "**c)** Nutze diese Möglichkeit, $\\alpha$ verändern zu können, um das optimale $\\alpha$ zu schätzen. Skizziere dann per Hand eine PRC- und eine ROC-Kurve. Überlege Dir dafür auch, was in den Grenzfällen $\\alpha=0$ und $\\alpha=1$ passiert. Gib dann eine zweite Schätzung für den optimalen Wert von $\\alpha$, basierend auf deiner Skizze, an."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yUR-Co8e2kG",
        "cellView": "form"
      },
      "source": [
        "#@markdown Ihr müsst diese Zelle nur ausführen, der Code ist nicht weiter interessant\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, Layout\n",
        "\n",
        "random.seed(0)\n",
        "pal = sns.color_palette(\"colorblind\")\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def inv_sigmoid(x):\n",
        "  return np.log(x/(1-x))\n",
        "\n",
        "x = np.linspace(-10, 10, num=1601)\n",
        "f1 = sigmoid(x)\n",
        "\n",
        "def update(alpha):\n",
        "  plt.figure(figsize=(24,12))\n",
        "  plt.plot(x,f1,lw=2)\n",
        "  plt.hlines(alpha, -10, np.log(alpha/(1-alpha)),colors=pal[2],lw=3)\n",
        "  tp = 10**(-6)\n",
        "  fp = 10**(-6)\n",
        "  fn = 10**(-6)\n",
        "  tn = 10**(-6)\n",
        "  for p,y in zip(predictions,y_true):\n",
        "    if y==0:    \n",
        "      if p < alpha:\n",
        "        plt.vlines(inv_sigmoid(p),0,p,colors=pal[0],alpha=0.2)\n",
        "        tn += 1\n",
        "      else:\n",
        "        plt.vlines(inv_sigmoid(p),0,p,colors=pal[0])\n",
        "        fp += 1\n",
        "    else: \n",
        "      if p >= alpha:\n",
        "        plt.vlines(inv_sigmoid(p),0,p,colors=pal[1])\n",
        "        tp += 1\n",
        "      else:\n",
        "        plt.vlines(inv_sigmoid(p),0,p,colors=pal[1],alpha=0.2)\n",
        "        fn += 1\n",
        "  tex = 'TPR: ' + str(int(1000*(tp+10**(-6))/(tp+fn+10**(-6)))/1000) + '\\nFPR: ' + str(int(1000*(fp+10**(-6))/(fp+tn+10**(-6)))/1000) + '\\nPrecision: ' + str(int(1000*(tp+10**(-6))/(tp+fp+10**(-6)))/1000) + '\\nRecall: ' + str(int(1000*(tp+10**(-6))/(tp+fn+10**(-6)))/1000)\n",
        "  if alpha > 0.8:\n",
        "    tex_y = 0.6\n",
        "  else:\n",
        "    tex_y = 0.8\n",
        "  plt.text(-8,tex_y,tex,fontsize=20)\n",
        "\n",
        "interact(update, alpha = widgets.FloatSlider(value=0.5,min=0.005, max=0.995, step = 0.01,layout=Layout(width='1000px')))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vilJ-5eXBm87"
      },
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, alphas = roc_curve(y_true, predictions) # overall 624 samples\n",
        "opt_roc_point = np.argmax(tpr-fpr)\n",
        "auroc = auc(fpr, tpr)\n",
        "\n",
        "alpha_string = \"{:.2f}\".format(alphas[opt_roc_point])\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "lw = 4\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % auroc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', label='random classifier')\n",
        "plt.plot(0,1,'g.',ms=20)\n",
        "plt.plot(fpr[opt_roc_point],tpr[opt_roc_point],'rX',ms=20)\n",
        "plt.text(fpr[opt_roc_point]-0.05,tpr[opt_roc_point]+0.05,r'$\\alpha$ = '+ alpha_string,color='red',size=30)\n",
        "plt.xlim([-0.02, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate',fontsize=20)\n",
        "plt.ylabel('True Positive Rate',fontsize=20)\n",
        "plt.title('Receiver Operating Characteristic',fontsize=20)\n",
        "plt.legend(loc=\"lower right\",fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADUF34O7COKa"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "prec, rec, betas = precision_recall_curve(y_true, predictions)\n",
        "opt_prc_point = np.argmax(prec+rec)\n",
        "auprc = auc(rec,prec)\n",
        "\n",
        "beta_string = \"{:.2f}\".format(betas[opt_prc_point])\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot([0, 1], [prec[0], prec[0]], color='navy', linestyle='--', label='random classifier',lw=lw)\n",
        "plt.plot(rec, prec, color='darkorange', lw=lw, label='PRC curve (area=%0.2f)' % auprc)\n",
        "plt.plot(1,prec[0],'r.',ms=20)\n",
        "plt.text(0.95,0.55,r'$\\frac{P}{P+N}$',color='red',size=30)\n",
        "plt.plot(1,1,'g.',ms=20)\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.plot(rec[opt_prc_point],prec[opt_prc_point],'rX',ms=20)\n",
        "plt.text(rec[opt_prc_point]-0.075,prec[opt_prc_point]+0.05,r'$\\alpha$ = '+ beta_string,color='red',size=30)\n",
        "plt.xlabel('Recall',fontsize=20)\n",
        "plt.ylabel('Precision',fontsize=20)\n",
        "plt.title('Precision Recall Characteristic',fontsize=20)\n",
        "plt.legend(loc='lower right',fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5qP03NRc-Ev"
      },
      "source": [
        "# 2. Validierungsverfahren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrtfvJPWRfgS"
      },
      "source": [
        "**a)** Führe die folgende Zelle aus, um die beiden Datensätze *data_for_training.csv* und *data_for_testing.csv* zu importieren. Bei den Daten handelt es sich um einen zufälligen Split eines Datensatzes für [Weinqualität](https://www.kaggle.com/vishalkumbhar1997/wine-quality-prediction-with-logistic-regression). Die Aufgabe besteht darin, einen Klassifikator zu erstellen, der aus den Features die Qualität (`quality`) richtig erkennt. Die Qualität ist dabei für diese Aufgabe binär in gut (1) und schlecht (0) codiert. Führe dann die nächste Zelle aus. Diese erstellt mit der Bibliothek `sklearn` einen Entscheidungsbaum (Der ist das Thema der nächsten Vorlesung, die genaue Funktionsweise ist für diese Übung nicht wichtig), trainiert ihn auf dem Datensatz *data_for_training.csv* und testet ihn dann auf dem Datensatz *data_for_testing.csv*. Wie ihr seht, ist der Score (hier wird standardmäßig die Accuracy berechnet) auf dem zweiten Datensatz deutlich niedriger. Hier liegt also Overfitting vor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCPlynEpdGwY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "train_wines = pd.read_csv('/content/gdrive/MyDrive/data_for_training.csv')\n",
        "test_wines = pd.read_csv('/content/gdrive/MyDrive/data_for_testing.csv')\n",
        "\n",
        "train_wines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQWG8uDqjKmT"
      },
      "source": [
        "y = train_wines['quality']\n",
        "X = train_wines.drop('quality',axis=1)\n",
        "\n",
        "y_test = test_wines['quality']\n",
        "X_test = test_wines.drop('quality',axis=1)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier().fit(X,y)\n",
        "\n",
        "# training und validation accuracy\n",
        "print(\"Tree with depth \" + str(tree.get_depth()) + \"; train score: \"+str(tree.score(X,y)) + \"; val score: \"+str(tree.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIa3rofTe2CS"
      },
      "source": [
        "**b)** Teile den Datensatz *data_for_training.csv* in einen Trainings- und einen Validierungsdatensatz auf. Der Datensatz *data_for_testing.csv* wird fürs erste nicht weiter beachtet. Nutze die in der Vorlesung vorgestellten Mehtoden der Validierung und Kreuzvalidierung um Hyperparameterkonfigurationen zu finden, die weniger overfitten als die Standardkonfiguration. \n",
        "\n",
        "**Hinweis:** Der Entscheidungsbaum hat verschiedene Hyperparamter, unter anderem die maximale Baumtiefe (`max_depth`) und das Teilungskriterium (`criterion`). Man kann zum Beispiel auch spezifizieren, wie viele Parameter bei jeder Teilung berücksichtigt werden sollen (`max_features`). Die Erklärung aller Parameter kann [hier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) nachgelesen werden. Ihr könnt euch bei dieser Aufgabe aber auch auf einen Parameter (z.B. `max_depth`) konzentrieren und für den einen optimalen Wert finden.\n",
        "\n",
        "**Hinweis2:** Die Bibliothek `sklearn` liefert viele Optionen zur Hyperparameteroptimierung und Validierung. Bei Interesse findet ihr [hier](https://scikit-learn.org/stable/modules/cross_validation.html) und [hier](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) weitere Infos. Die Klasse `sklearn.model_selection.cross_val_score` bietet z.B. die Möglichkeit, unterschiedliche und sogar eigene Gütekriterien bei der Kreuzvalidierung zu berechen. Hier kann man einfach ein bisschen ausprobieren!\n",
        "\n",
        "**c)** Teste deinen fertigen Klassifikator auf dem bei b) nicht berücksichtigten Datensatz *data_for_testing.csv*. Wie gut ist dein Ergebnis?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLDWSy4ndnL6"
      },
      "source": [
        "training_set = train_wines.sample(frac=0.8,random_state=0)\n",
        "validation_set = train_wines.drop(training_set.index,axis=0)\n",
        "\n",
        "y_train = training_set['quality']\n",
        "X_train = training_set.drop('quality',axis=1)\n",
        "\n",
        "y_val = validation_set['quality']\n",
        "X_val = validation_set.drop('quality',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmK_Q7_FUp5p"
      },
      "source": [
        "# Hyperparameter Optimierung der max_depth mit einfacher Validierung\n",
        "trees = []\n",
        "val_scores = []\n",
        "min_tree_depth = 1\n",
        "max_tree_depth = 31\n",
        "for i in range(min_tree_depth,max_tree_depth):\n",
        "  trees.append(DecisionTreeClassifier(max_depth=i).fit(X_train,y_train))\n",
        "  val_scores.append(trees[i-min_tree_depth].score(X_val,y_val))\n",
        "best_index = np.argmax(val_scores)\n",
        "# da wir unseren Baum jetzt nicht mehr verändern, können wir ihn nochmal neu trainieren, dieses mal auf allen Trainingsdaten\n",
        "best_tree = trees[best_index].fit(X,y)\n",
        "print(str(best_tree) + \"; valid score: \"+str(val_scores[best_index])+ \"; test score: \"+str(best_tree.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrsRr0patmVl"
      },
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plot_tree(best_tree)\n",
        "\n",
        "# Spalte 12: \"alcohol\", Spalte 3: \"volatile acidity\", Spalte 7: \"free sulfur dioxide\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFh307gYucAR"
      },
      "source": [
        "training_set.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUCGH-umYyix"
      },
      "source": [
        "# Hyperparameter Optimierung von max_depth, criterion, max_features, splitter mit einfacher Validierung\n",
        "trees = []\n",
        "val_scores = []\n",
        "counter = 0\n",
        "mds = range(1,31)\n",
        "cs = [\"gini\", \"entropy\"]\n",
        "mfs = [\"sqrt\", \"log2\", 0.25, 0.5, 0.75, None]\n",
        "sps = [\"best\", \"random\"]\n",
        "for i in mds:\n",
        "  for j in cs:\n",
        "    for k in mfs:\n",
        "      for s in sps:\n",
        "        trees.append(DecisionTreeClassifier(max_depth=i,criterion=j,splitter=s,max_features=k).fit(X_train,y_train))\n",
        "        val_scores.append(trees[counter].score(X_val,y_val))\n",
        "        counter += 1\n",
        "best_index = np.argmax(val_scores)\n",
        "best_tree = trees[best_index].fit(X,y)\n",
        "print(str(best_tree) + \"; valid score: \"+str(val_scores[best_index])+ \"; test score: \"+str(best_tree.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6rlJglAsISS"
      },
      "source": [
        "# Hyperparameter Optimierung der max_depth mit 5-facher Kreuzvalidierung\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "trees = []\n",
        "mean_cross_val_scores = []\n",
        "min_tree_depth = 1\n",
        "max_tree_depth = 31\n",
        "for i in range(min_tree_depth,max_tree_depth):\n",
        "  # wir können hier zur Bewertung jetzt alle Daten aus dem Trainingsset nehmen und brauchen keine Unterteilung in Train/Validation mehr; \n",
        "  # außerdem fitten wir den Baum nicht, das erledigt die Fkt cross_val_score automatisch\n",
        "  trees.append(DecisionTreeClassifier(max_depth=i)) \n",
        "  mean_cross_val_scores.append(np.mean(cross_val_score(trees[i-min_tree_depth],X,y,cv=5)))\n",
        "best_index = np.argmax(mean_cross_val_scores)\n",
        "best_tree = trees[best_index].fit(X,y)\n",
        "print(str(best_tree) + \"; mean cross valid score: \"+str(best_tree.score(X_val,y_val))+ \"; test score: \"+str(best_tree.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvXRF775tDzI"
      },
      "source": [
        "# Hyperparameter Optimierung von max_depth, criterion, max_features, splitter mit 5-facher Kreuzvalidierung\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "trees = []\n",
        "mean_cross_val_scores = []\n",
        "counter = 0\n",
        "mds = range(1,31)\n",
        "cs = [\"gini\", \"entropy\"]\n",
        "mfs = [\"sqrt\", \"log2\", 0.25, 0.5, 0.75, None]\n",
        "sps = [\"best\", \"random\"]\n",
        "for i in mds:\n",
        "  for j in cs:\n",
        "    for k in mfs:\n",
        "      for s in sps:\n",
        "        trees.append(DecisionTreeClassifier(max_depth=i,criterion=j,splitter=s,max_features=k)) \n",
        "        mean_cross_val_scores.append(np.mean(cross_val_score(trees[counter],X,y,cv=5)))\n",
        "        counter += 1\n",
        "best_index = np.argmax(mean_cross_val_scores)\n",
        "best_tree = trees[best_index].fit(X,y)\n",
        "print(str(best_tree) + \"; mean cross valid score: \"+str(best_tree.score(X_val,y_val))+ \"; test score: \"+str(best_tree.score(X_test,y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS9LkPTRvUHh"
      },
      "source": [
        "# Hyperparameter Optimierung der max_depth mit 5-facher Kreuzvalidierung; Optimiert wird dieses mal nach gewichtetem F1-score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "trees = []\n",
        "mean_cross_val_scores = []\n",
        "min_tree_depth = 1\n",
        "max_tree_depth = 31\n",
        "for i in range(min_tree_depth,max_tree_depth):\n",
        "  # wir können hier zur Bewertung jetzt alle Daten aus dem Trainingsset nehmen und brauchen keine Unterteilung in Train/Validation mehr; \n",
        "  # außerdem fitten wir den Baum nicht, das erledigt die Fkt cross_val_score automatisch\n",
        "  trees.append(DecisionTreeClassifier(max_depth=i)) \n",
        "  mean_cross_val_scores.append(np.mean(cross_val_score(trees[i-min_tree_depth],X,y,cv=5,scoring='f1_weighted')))\n",
        "best_index = np.argmax(mean_cross_val_scores)\n",
        "best_tree = trees[best_index].fit(X,y)\n",
        "y_test_predictions = best_tree.predict(X_test)\n",
        "print(str(best_tree) + \"; mean cross valid score (f1_weighted): \"+str(best_tree.score(X_val,y_val))+ \"; test score (f1_weighted): \"+str(f1_score(y_test,y_test_predictions,average='weighted')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}